{
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'spam-mails-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F109196%2F260807%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240416%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240416T102235Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Da5ef36a7b409e3bda09350cd0ba8ab4bb39b633756ec01fc8abb790653e4aca4444b9bfcbfdfa63baf338c5163d00888b6ff327b2b22cf194cd690dee1bcce353737979d75395f0c84e08995ada4aa3978dc90c65573c4e023d1fc7b922c891f0c5c5e42b01ae5b2e7359ccdc671b87ec7a9307d502119fc64cf8c614317c7bf8b28c3cb092f65354226df88d262cbd3c93b89a1eabfb14a7b549d727276e943bbbffd7491502ccc063e2801f730c22e555dcb14935e19b2578573b9c643f30343a8fb76258dba46ed0f29ba79ca7aa610266babd0b69e240f7a3367265e55c3aad8b77da3a466b8056f6e49891b5ca483b059d9033c19d618261ce9a333c71a'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "eFLi8yd6bf9N"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "O8cD5dBkuPuZ"
      },
      "cell_type": "markdown",
      "source": [
        "# **Spam Mail Classifier**\n",
        "\n",
        "![alt text](https://miro.medium.com/max/1536/1*mzIPUxnxbzdjlJusLnkNRQ.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "cqK6knUiuht_"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "nE7pdbcyt5Ba",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Handling Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visialization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# For Text processing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# DL\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, BatchNormalization, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "#Accuracy Metrics\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8F2Rzv9ObNl"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading Data"
      ]
    },
    {
      "metadata": {
        "id": "Qrz2mhZvuK6d",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/spam-mails-dataset/spam_ham_dataset.csv')\n",
        "# Removing Unnecessary column\n",
        "df.drop('Unnamed: 0', axis=1, inplace = True)\n",
        "# Changing column names\n",
        "df.columns = ['label', 'text', 'class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4V4Ypj1SuxxR",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mhZnmyp8vsya",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKUn0dTczAv1",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sONgIfWCzH7o",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# No NaN in the data\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DB9ifKO7v7ji",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Barplot describes the count of the class labels\n",
        "plt.figure(figsize = (12, 6))\n",
        "sns.countplot(data = df, x = 'label');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Js3zMa8Bbf9b"
      },
      "cell_type": "markdown",
      "source": [
        "## Viewing samples of the data"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Bas4yQtubf9c"
      },
      "cell_type": "code",
      "source": [
        "# Let's see few examples of the data\n",
        "\n",
        "for i in df.iterrows():\n",
        "    print(\"Class Label: {}\\nMail: \\n{}\\n\\n\".format(i[1][0], i[1][1]))\n",
        "    if i[0] == 6: break\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4BZWS-zY2h_M"
      },
      "cell_type": "markdown",
      "source": [
        "## Remove stopwords from the data"
      ]
    },
    {
      "metadata": {
        "id": "h7GU-Mhj3RYH",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([ word for word in word_tokenize(x)  if not word in stop_words]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQinq_gr4Gtk",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "63JwhjEF0WxE",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "X = df.loc[:, 'text']\n",
        "y = df.loc[:, 'class']\n",
        "\n",
        "print(f\"Shape of X: {X.shape}\\nshape of y: {y.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ydvg7VkF0FH-"
      },
      "cell_type": "markdown",
      "source": [
        "## Split data into **train** and **test** in 80:20"
      ]
    },
    {
      "metadata": {
        "id": "0oACJb0FwgQo",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8bb5GmWyaUA",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print(f\"Train Data Shape: {X_train.shape}\\nTest Data Shape: {X_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nj1asxUf1ceq"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess text to build the ML mdel"
      ]
    },
    {
      "metadata": {
        "id": "IeIRTO4k1Zmg",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "cVect = CountVectorizer()\n",
        "cVect.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IXpAECJD2I_S"
      },
      "cell_type": "markdown",
      "source": [
        "  Let's see the vocabulary that has extracted by hte count vextorizer"
      ]
    },
    {
      "metadata": {
        "id": "bg-bwb7713_n",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print('NO.of Tokens: ',len(cVect.vocabulary_.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bn43UCPJ2Qbj",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# document term vector (dtv)\n",
        "dtv = cVect.transform(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHqy7JQt44Ay",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "type(dtv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UpvPOMXW46Tk",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "dtv = dtv.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-eyUJKQ5KWa",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print(f\"Number of Observations: {dtv.shape[0]}\\nTokens/Features: {dtv.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9PsMu2D5PB9",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Let's see an sample that has been preprocessed\n",
        "dtv[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7nGnqpw4bf9l"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression.\n",
        "\n",
        "##### **Logistic Regression** could help use predict whether the student passed or failed. Logistic regression predictions are discrete (only specific values or categories are allowed). We can also view probability scores underlying the modelâ€™s classifications."
      ]
    },
    {
      "metadata": {
        "id": "R1yacI6Qbf9l"
      },
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "O6qZP9-8bf9m"
      },
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(verbose=1)\n",
        "\n",
        "grid={\"C\":[float(i) for i in range(1, 3)], \"penalty\":[\"l2\"], \"solver\":[ 'lbfgs', 'liblinear']}\n",
        "logreg_cv=GridSearchCV(lr, grid, cv=4)\n",
        "logreg_cv.fit(dtv,y_train)\n",
        "\n",
        "print(\"Tuned Hpyerparameters :\",logreg_cv.best_params_)\n",
        "print(\"accuracy :\",logreg_cv.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gyh2ZsoU6B4a",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "lr = LogisticRegression(solver='liblinear', penalty ='l2' , C = 1.0)\n",
        "lr.fit(dtv, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QU5GGLFA_dAY"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate on the Test data"
      ]
    },
    {
      "metadata": {
        "id": "bLmYtS1N64UU",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Preprocess the test data\n",
        "test_dtv = cVect.transform(X_test)\n",
        "test_dtv = test_dtv.toarray()\n",
        "print(f\"Number of Observations: {test_dtv.shape[0]}\\nTokens/Features: {test_dtv.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xEztQBTF_720",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pred = lr.predict(test_dtv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3pUmUbqAb91",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ', accuracy_score(y_test, pred) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TGwdpzQnAyKN"
      },
      "cell_type": "markdown",
      "source": [
        "  Classification Report of the classifier"
      ]
    },
    {
      "metadata": {
        "id": "taHJjDfSAkYs",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# 0 - Not Spam / Ham\n",
        "# 1 - Spam\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0PQUVsoBPIX"
      },
      "cell_type": "markdown",
      "source": [
        "  Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "id": "ue-vbeDICs-y",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "cmat = confusion_matrix(y_test, pred)\n",
        "plt.figure(figsize = (6, 6))\n",
        "sns.heatmap(cmat, annot = True, cmap = 'Paired', cbar = False, fmt=\"d\", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoTvO1fQOiKE"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict Class label for the unseen data i.e., Spam or Not Spam"
      ]
    },
    {
      "metadata": {
        "id": "B9T5vL8MEcJW",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# 'You won 1000$ prize money in lottery. Click here to avail'\n",
        "def predict_class(lr):\n",
        "    text = input('Enter Text(Subject of the mail): ')\n",
        "    text = [' '.join([ word for word in word_tokenize(text)  if not word in stop_words])]\n",
        "    t_dtv = cVect.transform(text).toarray()\n",
        "    print('Predicted Class:', end = ' ')\n",
        "    print('Spam' if lr.predict(t_dtv)[0] else 'Not Spam')\n",
        "    prob = lr.predict_proba(t_dtv)*100\n",
        "    print(f\"Not Spam: {prob[0][0]}%\\nSpam: {prob[0][1]}%\")\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x =['Not Spam', 'Spam'] , y = [prob[0][0], prob[0][1]])\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Probalility')\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTqU6h8dIgqg",
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "predict_class(lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AqIdZQqOCAS"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "936drD41bf9v"
      },
      "cell_type": "markdown",
      "source": [
        "### Do Upvote the Notebook, If you like."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Spam Mail Classifier"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}